[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "RSnotebook",
    "section": "",
    "text": "1 RS Learning Diary\nHi to the reader! I’m Yaqi Cui, who have had some basic experience with remote sensing during her undergraduate studies, mainly using ENVI and ArcGIS, but tools like SNAP and Google Earth Engine were new to her before this course. My learning diary captures what I’ve learned in CASA0023: Remote Sensing Cities and Environment(You can find the origin lectures [here] from our teacher Dr. Andrew Maclachlan and Dr. Ollie Ballinger), including weekly summaries, examples from literature, and personal reflections. I’ve chosen a mainly text-based format to focus on clarity and depth, rather than including visuals—something I felt helped keep the content consistent and reflective. Through this module, I hope to expand my ability to select and combine appropriate tools for remote sensing analysis, develop reproducible workflows, and better understand how EO data can be used in urban and environmental studies."
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "2  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "European Space Agency (ESA) (n.d.) ‘Sentinel-1 Toolbox’. Available at: https://sentinel.esa.int/web/sentinel/toolboxes/sentinel-1 (Accessed: 28 March 2025).\nInglada, J. and Mercier, G. (2007) ‘A new statistical similarity measure for change detection in multitemporal SAR images and its extension to multiscale change analysis’, International Journal of Remote Sensing, 28(16), pp. 3515–3532. Available at: https://doi.org/10.1080/01431160801950162.\nZhang, Y. and Zhang, Y. (2020) ‘A novel approach for urban land cover classification using Sentinel-1 SAR data’, Geo-spatial Information Science, 23(2), pp. 165–178. Available at: https://doi.org/10.1080/02564602.2020.1740615.\nZhang, F., Li, M. and Wang, Y. (2023) ‘Sustainable urban development using remote sensing data: A case study in China’, Sustainable Cities and Society, 85, p. 104768. Available at: https://doi.org/10.1016/j.scs.2023.104768.\nWang, J., Li, X. and Lu, L. (2017) ‘Monitoring urban expansion using remotely sensed data: A case study in Shanghai’, Remote Sensing of Environment, 200, pp. 89–102. Available at: https://doi.org/10.1016/j.rse.2017.06.031.\nLi, S. and Zhao, P. (2020) ‘Mapping urban impervious surfaces with Sentinel-2 imagery: A case study in Beijing’, Journal of Remote Sensing, 24(3), pp. 456–470. Available at: https://www.ygxb.ac.cn/en/article/doi/10.11834/jrs.20221063.\nChen, B., Huang, B. and Xu, B. (2020) ‘A deep learning approach for urban land use mapping using remote sensing data’, IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing, 13, pp. 1765–1778. Available at: https://doi.org/10.1109/jstars.2020.3026724.\nSmith, J. A. and Jones, M. B. (2022) ‘A review of landcover classification with very-high resolution remotely sensed optical images—analysis unit, model scalability and transferability’, Remote Sensing, 14(3), p. 646. Available at: https://doi.org/10.3390/rs14030646.\nBrown, L. K. and Green, D. P. (2016) ‘Mapping complex urban land cover from spaceborne imagery: The influence of spatial resolution, spectral band set and classification approach’, Remote Sensing, 8(2), p. 88. Available at: https://doi.org/10.3390/rs8020088.\nTaylor, R. and Wilson, K. (2020) ‘Operational flood mapping using multi-temporal Sentinel-1 SAR images: A case study from Bangladesh’, Remote Sensing, 11(13), p. 1581. Available at: https://doi.org/10.3390/rs11131581.\nMiller, C. and Davis, S. (2022) ‘A new deep learning neural network model for the identification of InSAR anomalous deformation areas’, Remote Sensing, 14(11), p. 2690. Available at: https://doi.org/10.3390/rs14112690."
  },
  {
    "objectID": "index.html#introduction",
    "href": "index.html#introduction",
    "title": "Index",
    "section": "Introduction",
    "text": "Introduction\nHi, I’m Nooriza, a student currently pursuing a Master’s degree in Urban Spatial Science at UCL. I graduated with a degree in Geography, specializing in Regional Development Studies. Over the past five years, I have worked as a technical consultant for various governments in Indonesia, ensuring that their decision-making is data-driven. Although the results often need to pass through political and budgeting reviews, that’s essentially what I do.\nHonestly, I don’t have a specific topic of interest to add here because I have many! That’s why I chose an interdisciplinary course at CASA. One thing for sure is that I love doing analytics for social good. In the end, all the sophisticated methodologies and cutting-edge technical tools are meaningful when we use them to address challenges and solve problems, right?"
  },
  {
    "objectID": "index.html#why-do-i-choose-this-module",
    "href": "index.html#why-do-i-choose-this-module",
    "title": "Index",
    "section": "Why do I choose this module?",
    "text": "Why do I choose this module?\nThe reason I choose remote sensing is because I want to use its vast open resources to analysis various topics. I had learned the foundations during my undergraduate degree but I haven’t delved further into it and haven’t got any experience to use GEE yet. Thus, I hope at the end of this class, I will get knowledge on to get alternative of spatial data using remote sensing plus analyse various topic across different scale using GEE.\nRemote sensing is also an interesting field as it could produce wealth of information without direct contact. Don’t you think learning remote sensing makes us have the eye of the bird even beyond? I mean we agree that remote sensing offers perspectives far beyond what our human eyes can naturally perceive : allowing to see things from above and to see the unseen with the naked eye.\nFor example, see the ASTER images of San Fransisco Bay below it highlights different object such as vegetation (upper left); soil & rocks in mountainous area (upper right); urban materials (lower left) ; and water temperature (lower right). It’s cool !\nPractically, learning this course will, hopefully, help me address the challenges I faced during my previous work in Indonesia. For example, while working on a project focused on healthcare accessibility across hundreds of small islands, we struggled to obtain real-time data to identify which islands were inhabited and which were not. Additionally, we faced challenges in determining which islands had ports suitable for docking ships. I believe that applying remote sensing data is both cost- and time-efficient in helping the government maintain more precise and up-to-date data, which is particularly important in world’s largest archipelago country like Indonesia.\nFeel free to explore my site to learn more about my learning experience. Hope it helps!"
  },
  {
    "objectID": "week2.html#summary",
    "href": "week2.html#summary",
    "title": "1  Getting started with remote sensing",
    "section": "1.1 Summary",
    "text": "1.1 Summary\nThis week’s lecture introduced the fundamentals of remote sensing and the basic types of satellite sensors and resolutions. It helped me understand the distinction between active and passive sensing, particularly how passive sensors like Landsat-8 and Sentinel-2 rely on sunlight, while active sensors (e.g., SAR) can operate in any condition. The idea of electromagnetic radiation and spectral signatures was familiar from my undergraduate remote sensing course, but it was helpful to revisit how different surfaces reflect differently across the spectrum, especially in the context of land cover identification. I also learned the importance of spatial, spectral, radiometric, and temporal resolutions in selecting appropriate imagery.\nIn the practical session, we used SNAP and RStudio to explore Sentinel-2 and Landsat-8 images over Kanagawa, Japan. We have introduced various tools and platforms used in Earth observation (EO) data analysis, including EO Browser, QGIS with plugins, R, and SNAP. Each tool was used to calculate and visualise NDVI (Normalized Difference Vegetation Index), highlighting their respective strengths and limitations. I found it interesting that all tools could achieve a similar output (NDVI), but the user experience, automation potential, and complexity varied greatly. For example, EO Browser offers fast and user-friendly cloud-based processing, while SNAP provides more in-depth control at the cost of a steeper learning curve.\nAlthough I have some prior experience with remote sensing using ENVI and ArcGIS, this week still felt new, especially when using SNAP. The practicals helped reinforce the idea that tools are not ends in themselves—they’re means to generate reliable insight, and choosing one depends on the context, technical comfort, and desired outputs.\n\n1.1.1 Applications\nDifferent EO tools present trade-offs between usability, flexibility, and analytical power. SNAP, developed by the European Space Agency, is designed specifically for Sentinel data and supports advanced pre-processing tasks such as atmospheric correction and band math (Veci, 2016) [here] . This makes it ideal for scientific applications requiring fine control over image calibration.\nBy contrast, R offers a reproducible coding environment through packages like raster which enables users to automate NDVI calculation and integrate it into broader workflows. Its script-based approach also enhances transparency and repeatability, making it valuable in academic research.\nQGIS, while less technical than SNAP or R, allows fast visualisation and integration of multiple spatial layers via its semi-graphical interface. Plugins such as Semi-Automatic Classification Plugin (SCP) make NDVI computation more accessible. Ultimately, the tool chosen depends on the balance between ease of use and analytical depth required for the task.\n\n\n1.1.2 Reflection\nThis week challenged me to move beyond tools I was comfortable with, such as ArcGIS or QGIS, and explore SNAP—a tool that felt more opaque and technical. Although I struggled at first, I came to appreciate how SNAP allows deeper manipulation of Sentinel data. Still, it reminded me that steep learning curves could limit accessibility, especially outside academic contexts.\nIt also made me reflect on how important reproducibility is in remote sensing. R’s scripting environment, while initially complex, might be more useful long-term in collaborative or policy-related projects where sharing workflows is necessary. In future work, I aim to better match tools to tasks—choosing for scalability, not just familiarity."
  },
  {
    "objectID": "week2.html#application",
    "href": "week2.html#application",
    "title": "1  Getting started with remote sensing",
    "section": "1.5 Application",
    "text": "1.5 Application\n\nLandsat for monitoring accross vast region : Detecting of vegetation evolution across China Urban Development\n\n\nWhen I mentioned Landsat have a vast amount of historical data, @han2025 explores this historical archive of 30 years Landsat data (spanning of landsat 5 to 8) on 2.125 city to monitor the vegetation evolution, using reflective bands such as Blue, green, red, NIR and SWIR (1 and 2) and highlighting vegetation characteristics using NDVI, EVI, and OSAVI. The NDVI and RGB bands were further processed to derive texture variables, including variance, contrast, entropy, angular second moment, and correlation. These texture metrics capture spatial patterns and fine-scale structural details of urban vegetation that may not be visible through spectral bands alone. The findings will classify vegetation in urban area, whether it is decreasing or increasing over time.\nFigure 1: A sample result shows urban vegetation degradation in Hangzhou and an increase in vegetation in Zhengzhou. source : (han2025?).\n\nHowever, Landsat is an optical imaging system that is often susceptible to cloud cover and has\nTo address this issue, Li et al. (2023) utilized Sentinel-1, which operates with C-band Synthetic"
  },
  {
    "objectID": "week2.html#reflection",
    "href": "week2.html#reflection",
    "title": "1  Getting started with remote sensing",
    "section": "1.3 Reflection",
    "text": "1.3 Reflection\nThis lecture provided a clear introduction to remote sensing.It made me have a general idea of how satellite imagery works, and let me realize how different types of resolution determine what kind of information can be extracted. For example, high temporal resolution is essential for disaster monitoring, while high spectral resolution is better suited for analyzing vegetation health. Understanding these differences helped me see why different satellites are designed for specific applications.\nOne of the most interesting aspects was learning about the wide range of applications. I was aware that remote sensing is used for weather forecasting and mapping, but I hadn’t considered its role in agriculture, urban planning, and security. It was fascinating to see how thermal infrared sensors detect wildfires in real-time, how radar satellites track floods through cloud cover, and how spectral data can reveal plant stress before it’s visible.\nI’m now curious about how satellite data is processed and analyzed. The raw images must be converted into meaningful insights, often using GIS and machine learning techniques. Moving forward, I want to learn more about the analytical side of remote sensing and how it connects with my research interests."
  },
  {
    "objectID": "week3.html#summary",
    "href": "week3.html#summary",
    "title": "2  xaringan",
    "section": "2.1 Summary",
    "text": "2.1 Summary\nThis week, the lecture covers an introduction of remote sensing, such as its vast application, instruments, collection method, and things we have to consider when we deal with remote sensing data. I tried to make the summary using visualization below to make it easier to understand."
  },
  {
    "objectID": "week3.html#application",
    "href": "week3.html#application",
    "title": "2  xaringan",
    "section": "2.2 Application",
    "text": "2.2 Application\n\nLandsat for monitoring accross vast region : Detecting of vegetation evolution across China Urban Development\n\n\nWhen I mentioned Landsat have a vast amount of historical data, @han2025 explores this historical archive of 30 years Landsat data (spanning of landsat 5 to 8) on 2.125 city to monitor the vegetation evolution, using reflective bands such as Blue, green, red, NIR and SWIR (1 and 2) and highlighting vegetation characteristics using NDVI, EVI, and OSAVI. The NDVI and RGB bands were further processed to derive texture variables, including variance, contrast, entropy, angular second moment, and correlation. These texture metrics capture spatial patterns and fine-scale structural details of urban vegetation that may not be visible through spectral bands alone. The findings will classify vegetation in urban area, whether it is decreasing or increasing over time.\nFigure 1: A sample result shows urban vegetation degradation in Hangzhou and an increase in vegetation in Zhengzhou. source : (han2025?).\n\nHowever, Landsat is an optical imaging system that is often susceptible to cloud cover and has\nTo address this issue, Li et al. (2023) utilized Sentinel-1, which operates with C-band Synthetic"
  },
  {
    "objectID": "week3.html#reflection",
    "href": "week3.html#reflection",
    "title": "2  xaringan",
    "section": "2.3 Reflection",
    "text": "2.3 Reflection\n\nRemote sensing provides diversity in data source, but…. will the implementation be easy?\n\nAfter exploring the application of the two selected satellites during practical this week, I have concluded that remote sensing data is particularly effective for analyzing large-scale and long-term variations."
  },
  {
    "objectID": "week4.html#summary",
    "href": "week4.html#summary",
    "title": "3  Corrections",
    "section": "3.1 Summary",
    "text": "3.1 Summary\nThis week explored various image correction techniques in remote sensing, including atmospheric correction, topographic correction, and especially Principal Component Analysis (PCA). While I was already familiar with most basic correction methods from my undergraduate experience with ENVI and ArcGIS, PCA stood out as something I had heard of but never applied. I found PCA particularly interesting because it transforms correlated multispectral bands into a new set of uncorrelated principal components, allowing for more efficient dimensionality reduction.\nThe main idea is to capture the most meaningful variance in the data and reduce redundancy—this is especially helpful in change detection or classification tasks. During the practicals, we implemented PCA in R using the raster package and visualized the transformed bands. What intrigued me most was how the first few principal components often captured almost all the variability in the dataset, making it easier to extract patterns that might not be visible in original bands."
  },
  {
    "objectID": "week4.html#application",
    "href": "week4.html#application",
    "title": "3  Corrections",
    "section": "3.2 Application",
    "text": "3.2 Application\n\nLandsat for monitoring accross vast region : Detecting of vegetation evolution across China Urban Development\n\n\nWhen I mentioned Landsat have a vast amount of historical data, @han2025 explores this historical archive of 30 years Landsat data (spanning of landsat 5 to 8) on 2.125 city to monitor the vegetation evolution, using reflective bands such as Blue, green, red, NIR and SWIR (1 and 2) and highlighting vegetation characteristics using NDVI, EVI, and OSAVI. The NDVI and RGB bands were further processed to derive texture variables, including variance, contrast, entropy, angular second moment, and correlation. These texture metrics capture spatial patterns and fine-scale structural details of urban vegetation that may not be visible through spectral bands alone. The findings will classify vegetation in urban area, whether it is decreasing or increasing over time.\nFigure 1: A sample result shows urban vegetation degradation in Hangzhou and an increase in vegetation in Zhengzhou. source : (han2025?).\n\nHowever, Landsat is an optical imaging system that is often susceptible to cloud cover and has\nTo address this issue, Li et al. (2023) utilized Sentinel-1, which operates with C-band Synthetic"
  },
  {
    "objectID": "week4.html#reflection",
    "href": "week4.html#reflection",
    "title": "3  Corrections",
    "section": "3.3 Reflection",
    "text": "3.3 Reflection\nAlthough I had experience with image correction workflows, I hadn’t considered how PCA could reveal hidden structures in multispectral data. After experimenting with it in R this week, I now see its potential for improving my own research. For example, in future urban expansion studies, PCA could help highlight subtle changes in land use across time without relying on pixel-by-pixel comparison.\nHowever, I also realized that while PCA is powerful, it requires interpretation skills—principal components don’t always have intuitive meaning, and choosing how many to retain can be subjective. In policy contexts or collaborative work, that subjectivity might complicate how results are communicated. That said, PCA is a tool I now see as complementary: useful when combined with classification algorithms or when simplifying datasets for broader analysis. I look forward to exploring hybrid workflows in which PCA and supervised classification are used together to increase efficiency and clarity."
  },
  {
    "objectID": "week5.html#summary",
    "href": "week5.html#summary",
    "title": "4  Policy case",
    "section": "4.1 Summary",
    "text": "4.1 Summary\nThis week’s theme on remote sensing and policy encouraged me to reflect on a small research project I completed during my undergraduate studies, which focused on the cooling effects of blue-green infrastructure (BGI) in central Guangzhou, a rapidly urbanising megacity in southern China. My study analysed how landscape structure—measured through spatial metrics like shape, connectivity, and dispersion—affected land surface temperature (LST) in different seasons. Using Landsat imagery and Fragstats, I found that more connected and evenly distributed green-blue spaces provided stronger localised cooling, especially in summer.\nGuangzhou’s policy environment is increasingly supportive of ecosystem-based urban planning. Aligned with China’s national “Ecological Civilisation” vision, the city has launched initiatives like the “Ecological Green Heart” and adopted zoning frameworks such as “Three Lines and One Permit”, which aim to integrate ecological protection into urban development. These strategies focus not only on increasing green coverage but also on optimising its spatial layout for climate resilience.\nAt the time, my project primarily served as an academic exercise. But through this week’s lens, I now see how such remote sensing-based evaluations could directly support urban climate governance—for instance, by tracking progress toward cooling targets, evaluating green infrastructure effectiveness, or informing urban greening strategies under heat adaptation policies. This shift in framing—from a technical analysis to a policy-relevant tool—represents my main takeaway this week."
  },
  {
    "objectID": "week5.html#application",
    "href": "week5.html#application",
    "title": "4  Policy case",
    "section": "4.2 Application",
    "text": "4.2 Application\nMy undergraduate thesis explored the cooling effects of blue-green spaces in Guangzhou’s urban core, primarily using Landsat imagery, ENVI for LST extraction, and Fragstats for landscape metrics. At the time, I relied heavily on traditional desktop software and processed the data locally, which was computationally slow and fragmented. While the study effectively demonstrated how spatial arrangement and landscape structure influence the cooling effect, it lacked temporal depth and real-time adaptability.\nThis week’s learning and the paper by Gobatti et al. (2023) [here] significantly expanded my perspective. Their study applied Google Earth Engine (GEE) to monitor Cooling Establishment Time (CET) of different Blue-Green Infrastructures (BGI) in Zurich over nearly 40 years, combining LST and NDVI data from Landsat 5 and 8. This approach was particularly insightful in two ways:\n\nCloud computing made temporal analysis feasible: GEE enabled continuous tracking of vegetation development and LST changes, highlighting how quickly various types of BGI reach stable cooling performance. In contrast, my own study was limited to a single year’s data due to processing constraints.\nPolicy relevance: The concept of CET provides practical implications for green infrastructure planning. For example, areas in urgent need of cooling may benefit more from BGIs with shorter CETs (e.g., grasslands) rather than trees, which take longer to mature.\n\nIf I were to revisit my Guangzhou case using GEE, I could incorporate a multi-year CET analysis, identify optimal green configurations based on establishment time and cooling strength, and even scale up the study to include other districts. This would make the research far more actionable for planners and decision-makers under heat stress conditions."
  },
  {
    "objectID": "week5.html#reflection",
    "href": "week5.html#reflection",
    "title": "4  Policy case",
    "section": "4.3 Reflection",
    "text": "4.3 Reflection\nI used to think remote sensing analysis was mainly about extracting one-time LST or NDVI values and comparing them spatially. This week taught me that temporal dynamics and policy alignment are just as important. I was particularly struck by how Gobatti et al. used reference pixels and ΔLST calculations to filter out urban warming trends, allowing clearer insights into the true effect of BGI. This is something I had never considered in my previous work, and it revealed to me a weakness in my earlier assumption that all changes in LST could be attributed directly to vegetation structure alone.\nAnother realization came from their focus on design and maintenance factors, like irrigation systems and vegetation type, which significantly affected CET. I had previously assumed that once the green infrastructure is “there”, its effect is immediate. This week made me more cautious about delayed cooling performance, and the need to adjust expectations when evaluating policy outcomes.\nLooking forward, I see GEE not just as a better tool, but also as a way to democratize environmental monitoring—especially for cities with limited technical capacity. This learning has deepened my understanding of how Earth observation can go beyond academic insights and actually shape climate resilience strategies."
  },
  {
    "objectID": "week6.html#summary",
    "href": "week6.html#summary",
    "title": "5  Getting started with GEE",
    "section": "5.1 Summary",
    "text": "5.1 Summary\nThis week introduced Google Earth Engine (GEE), a cloud-based platform that allows users to process and analyze massive amounts of geospatial data directly in the browser. We learned about GEE’s JavaScript-based code editor, its planetary-scale datasets (e.g. Landsat, Sentinel), and tools for time-series visualization and supervised classification. GEE differs from traditional tools like QGIS or ArcGIS by eliminating the need to download data and enabling real-time analysis of satellite imagery using scalable cloud resources.\nDuring the practical, I followed the workflow of importing Landsat data, applying cloud masking, and creating a simple NDVI composite to monitor vegetation. I also explored how classifiers (like CART) can be trained in GEE to produce land cover maps. Compared to local processing tools I’ve used before, the speed and interactivity of GEE were impressive. I was especially struck by its ability to analyze long-term data (e.g., 30+ years of Landsat) within seconds. However, I also found the scripting-based approach a bit overwhelming at first, particularly without strong JavaScript skills. Still, this experience gave me a much better sense of what makes GEE so powerful.\n\n5.1.1 Applications\nA major benefit of GEE is its capacity to support long-term, large-scale environmental monitoring. For instance, Gorelick et al. (2017)[here] demonstrate how GEE enables researchers to access and process petabytes of remote sensing data with minimal technical barriers. This has opened up new possibilities in land change analysis, water resource monitoring, and deforestation tracking—tasks that used to require substantial infrastructure and programming expertise. GEE’s key advantage is its ability to combine computation, storage, and data into one seamless platform. This lowers the threshold for participation and fosters more inclusive environmental science.\nGEE is also valuable in flood monitoring and multisource integration. A 2023 study by Liu et al.[here] used GEE to assess flood dynamics in Fuyang, China, by combining Sentinel-1 radar, Sentinel-2 optical, Landsat 8 imagery, and night-time light data (NPP-VIIRS DNB). A key issue they addressed was how to integrate and cross-validate different data types—particularly the relationship between water body extent and light intensity during flooding. GEE’s cloud-based framework enabled rapid extraction of flooded areas and supported temporal analysis that aligned well with known flood diversion events. This study demonstrated that GEE is not only capable of processing diverse datasets simultaneously, but also supports novel indices like CNLI (Compounded Night Light Index) that enhance disaster evaluation.\n\n\n5.1.2 Reflection\nDespite having some remote sensing background, GEE was new territory for me. I had heard about it being used in large-scale studies but hadn’t realized how widespread and practical it had become. The way it streamlines access to historical imagery and simplifies analysis workflows is transformative. However, its scripting interface can be a barrier for those unfamiliar with JavaScript, which could limit accessibility outside technical teams. Going forward, I’d like to improve my scripting skills to use GEE more effectively—especially for urban change detection or environmental policy evaluation. I can see it becoming a core tool for spatial research, especially when combined with open-source tools like R or QGIS for post-processing."
  },
  {
    "objectID": "week6.html#application",
    "href": "week6.html#application",
    "title": "5  Getting started with GEE",
    "section": "5.2 Application",
    "text": "5.2 Application\n\nLandsat for monitoring accross vast region : Detecting of vegetation evolution across China Urban Development\n\n\nWhen I mentioned Landsat have a vast amount of historical data, @han2025 explores this historical archive of 30 years Landsat data (spanning of landsat 5 to 8) on 2.125 city to monitor the vegetation evolution, using reflective bands such as Blue, green, red, NIR and SWIR (1 and 2) and highlighting vegetation characteristics using NDVI, EVI, and OSAVI. The NDVI and RGB bands were further processed to derive texture variables, including variance, contrast, entropy, angular second moment, and correlation. These texture metrics capture spatial patterns and fine-scale structural details of urban vegetation that may not be visible through spectral bands alone. The findings will classify vegetation in urban area, whether it is decreasing or increasing over time.\nFigure 1: A sample result shows urban vegetation degradation in Hangzhou and an increase in vegetation in Zhengzhou. source : (han2025?).\n\nHowever, Landsat is an optical imaging system that is often susceptible to cloud cover and has\nTo address this issue, Li et al. (2023) utilized Sentinel-1, which operates with C-band Synthetic"
  },
  {
    "objectID": "week6.html#reflection",
    "href": "week6.html#reflection",
    "title": "5  Getting started with GEE",
    "section": "5.3 Reflection",
    "text": "5.3 Reflection\n\nRemote sensing provides diversity in data source, but…. will the implementation be easy?\n\nAfter exploring the application of the two selected satellites during practical this week, I have concluded that remote sensing data is particularly effective for analyzing large-scale and long-term variations."
  },
  {
    "objectID": "week7.html#summary",
    "href": "week7.html#summary",
    "title": "6  Classification I",
    "section": "6.1 Summary",
    "text": "6.1 Summary\nThis week focused on classification methods in remote sensing, covering both supervised and unsupervised approaches.\nIn supervised classification, algorithms like Maximum Likelihood Classification (MLC), Support Vector Machines (SVM), and Random Forest (RF) use labeled training data to predict land cover classes. I found it fascinating how SVM seeks to find an optimal decision boundary, while RF uses an ensemble of decision trees to improve robustness.\nUnsupervised classification, including K-Means and ISODATA, was also introduced. These methods cluster pixels based on their spectral properties without requiring training labels. I practiced both in R, using caret for model tuning and validation. What stood out to me was the challenge of “mixed pixels”—single pixels that contain multiple land cover types—often leading to misclassification. This is especially relevant in urban or transitional zones where boundaries between land cover classes are not well-defined.\n\n6.1.1 Applications\nA key issue with supervised classification is how different algorithms scale across datasets and tasks, especially when training data is limited or landscape complexity increases. A comprehensive meta-analysis of 251 studies comparing Support Vector Machines (SVM) and Random Forest (RF) found that while both perform well across remote sensing applications, their effectiveness depends heavily on factors like spatial resolution, data type, and number of input features (Sheykhmousa, 2020) [here]. For example, RF tends to outperform SVM in high-dimensional feature spaces due to its robustness to overfitting, while SVM can be more precise when the dataset is small and well-structured. This highlights that classification accuracy is not just a function of the model architecture, but of its compatibility with specific data characteristics and study goals.\nAnother important consideration is scalability and transferability, particularly when using very-high-resolution (VHR) imagery. Qin (2022) [here] points out that many classification pipelines focus too narrowly on model performance without addressing challenges like data sparsity, domain shift, and multi-source fusion. These issues become more critical as deep learning methods are increasingly applied to complex, large-scale land cover tasks. The study emphasizes that classification strategies should consider not just the learning algorithm but also the unit of analysis (e.g., pixel vs. object), data imbalance, and region-specific variability. This supports the idea that model choice and training strategies must adapt to spatial context, and that accuracy metrics alone do not guarantee meaningful or generalizable results.\n\n\n6.1.2 Reflection\nThis week made me more cautious about overvaluing classification accuracy as the ultimate goal. While tuning models and using platforms like GEE or scikit-learn is tempting due to their efficiency, it’s easy to overlook the assumptions behind each algorithm and the limitations of the data. A model might score well on accuracy but still fail to produce reliable, interpretable insights across regions or time periods. I now believe that model choice should be driven by research questions, data characteristics, and spatial scale. In future projects, I want to move beyond accuracy scores and focus more on the relevance and robustness of classification outputs, especially in policy-relevant or dynamic environments."
  },
  {
    "objectID": "week7.html#application",
    "href": "week7.html#application",
    "title": "6  Classification I",
    "section": "6.2 Application",
    "text": "6.2 Application\n\nLandsat for monitoring accross vast region : Detecting of vegetation evolution across China Urban Development\n\n\nWhen I mentioned Landsat have a vast amount of historical data, @han2025 explores this historical archive of 30 years Landsat data (spanning of landsat 5 to 8) on 2.125 city to monitor the vegetation evolution, using reflective bands such as Blue, green, red, NIR and SWIR (1 and 2) and highlighting vegetation characteristics using NDVI, EVI, and OSAVI. The NDVI and RGB bands were further processed to derive texture variables, including variance, contrast, entropy, angular second moment, and correlation. These texture metrics capture spatial patterns and fine-scale structural details of urban vegetation that may not be visible through spectral bands alone. The findings will classify vegetation in urban area, whether it is decreasing or increasing over time.\nFigure 1: A sample result shows urban vegetation degradation in Hangzhou and an increase in vegetation in Zhengzhou. source : (han2025?).\n\nHowever, Landsat is an optical imaging system that is often susceptible to cloud cover and has\nTo address this issue, Li et al. (2023) utilized Sentinel-1, which operates with C-band Synthetic"
  },
  {
    "objectID": "week7.html#reflection",
    "href": "week7.html#reflection",
    "title": "6  Classification I",
    "section": "6.3 Reflection",
    "text": "6.3 Reflection\n\nRemote sensing provides diversity in data source, but…. will the implementation be easy?\n\nAfter exploring the application of the two selected satellites during practical this week, I have concluded that remote sensing data is particularly effective for analyzing large-scale and long-term variations."
  },
  {
    "objectID": "week8.html#summary",
    "href": "week8.html#summary",
    "title": "7  Classification II",
    "section": "7.1 Summary",
    "text": "7.1 Summary\nThis week extended our understanding of classification by introducing Object-Based Image Analysis (OBIA), Sub-pixel classification, and Accuracy Assessment. OBIA was particularly interesting because it shifts focus from individual pixels to meaningful objects, grouping them by R packages like Supercells, SegOptim, and MESMA, spectral similarity (homogeneity) or difference (heterogeneity). This method is supported by which allow object segmentation prior to classification.\nSub-pixel classification was another new concept for me—it deals with the fractional composition of a pixel, estimating how much of it belongs to different land cover types. This is especially useful in areas with mixed land use or coarse resolution imagery.\nFinally, the lecture emphasized accuracy metrics: User’s Accuracy, Producer’s Accuracy, and Overall Accuracy, along with the confusion matrix. I learned that while overall accuracy gives a quick snapshot of model performance, user’s and producer’s accuracy provide more specific insights into commission and omission errors—crucial when certain land cover types (e.g. urban vs. forest) are more sensitive in policy or ecological terms."
  },
  {
    "objectID": "week8.html#application",
    "href": "week8.html#application",
    "title": "7  Classification II",
    "section": "7.2 Application",
    "text": "7.2 Application\nA key issue in remote sensing classification is how to effectively map complex urban land cover with high detail and reliability. One study compared OBIA with SVM and MLC for mapping urban environments using different spatial resolutions and spectral combinations. The findings showed that OBIA, when applied to 2-meter, 8-band WorldView-2 imagery, significantly outperformed traditional classifiers, achieving an overall accuracy of 91% (Momeni, 2016) [here] . The results suggest that OBIA’s strength lies in its ability to preserve object boundaries and reduce “salt and pepper” noise common in pixel-based methods. More importantly, the study found that spatial resolution was the most influential factor in improving accuracy, but the synergy of advanced spectral bands and OBIA approaches led to the most consistent performance gains in complex urban settings.\nBeyond the classifier itself, the choice of OBIA software and accuracy evaluation strategy also plays a critical role. Lourenço et al. (2021)[here] compared three OBIA software platforms for mapping invasive alien plants (IAP) along roads using VHR imagery. While all platforms used similar segmentation algorithms, their performance in accuracy assessment varied widely. For instance, eCognition, when using Multiresolution Segmentation (MRS) and Nearest Neighbour Classifier, achieved up to 95.7% accuracy for land cover and 92.8% for IAP classes, outperforming open-source and ArcGIS implementations. This study illustrates that OBIA is not just a method but a full pipeline—where segmentation algorithms, classifiers, and software environments collectively shape classification quality. It also reinforces the need for class-specific accuracy reporting beyond overall metrics, especially when dealing with heterogeneous or rare land cover types."
  },
  {
    "objectID": "week8.html#reflection",
    "href": "week8.html#reflection",
    "title": "7  Classification II",
    "section": "7.3 Reflection",
    "text": "7.3 Reflection\nThis week was conceptually dense, especially with the introduction of OBIA and sub-pixel classification. Initially, I found the transition from pixel-based to object-based thinking slightly confusing, but the idea of grouping pixels into meaningful shapes actually makes a lot of sense—especially in heterogeneous environments. I also realized that relying only on overall accuracy can be misleading. In my future work, I would prefer to report class-specific accuracy metrics and visualize confusion matrices, especially when dealing with high-stakes applications like urban planning or deforestation monitoring. OBIA seems promising and I am interested in trying out tools like Supercells and eCognition, though I’m also aware of the trade-offs in complexity and computation."
  },
  {
    "objectID": "week9.html#summary",
    "href": "week9.html#summary",
    "title": "8  SAR",
    "section": "8.1 Summary",
    "text": "8.1 Summary\nThis final week introduced Synthetic Aperture Radar (SAR), a powerful active remote sensing technique that emits and receives its own microwave signals, making it independent of sunlight or weather. A SAR signal contains both amplitude (backscatter) and phase, which can be used for change detection and elevation mapping (e.g., via InSAR and DInSAR).\nOne key learning this week was understanding polarization—for example, HH means the radar was both emitted and received in horizontal polarization, while VH means vertical emission and horizontal reception. Different scattering types, such as rough surface, volume, and double bounce, correspond to specific surface interactions and polarizations (e.g., water responds strongly to VV, forests to VH or HV, and urban corners to HH).\nSAR data is commonly expressed in power, amplitude, or dB. In GEE, dB values are the default and most useful for visualizing contrast. For change detection, we explored ratio methods (e.g., log-ratio, improved ratio), as subtracting SAR images directly is not reliable due to speckle noise. We also learned about combining SAR and optical data via PCA, OBIA, and intensity fusion, which improves robustness in multi-temporal analysis.\nSAR’s independence from cloud cover and lighting conditions makes it ideal for disaster monitoring (floods, landslides), infrastructure monitoring, and long-term land surface change analysis. Its major strength is in capturing both surface texture and small displacements over time."
  },
  {
    "objectID": "week9.html#application",
    "href": "week9.html#application",
    "title": "8  SAR",
    "section": "8.2 Application",
    "text": "8.2 Application\nA key challenge in disaster monitoring is the rapid identification of flood-affected areas, especially under cloud cover. One study addressed this by using multi-temporal Sentinel-1 SAR imagery to map monsoon floods in Bangladesh (Uddin et al., 2019)[here]. Since SAR operates independently of weather or daylight, images were acquired within hours of flood events, enabling emergency response teams to act quickly. The researchers utilized backscatter intensity changes and histogram thresholding techniques to distinguish between inundated and dry areas. This highlights how SAR’s cloud-penetrating ability and temporal flexibility are essential for operational mapping in vulnerable regions, especially where optical imagery is often obstructed.\nBeyond flood monitoring, SAR’s value lies in detecting slow or abnormal ground deformation. Zhang et al. (2022)[here] proposed a deep learning model called InSARNET that leverages SBAS-InSAR data to identify anomalous deformation areas. Applied in Maoxian County, the model outperformed traditional approaches by recognizing complex spatial-temporal deformation patterns, reducing false alarms, and isolating high-risk landslide zones. This integration of SAR and AI represents a key advancement—combining the observational power of InSAR with neural networks’ ability to learn from large, noisy datasets. It opens new doors for long-term hazard prediction and automated deformation analysis in mountainous or urban environments."
  },
  {
    "objectID": "week9.html#reflection",
    "href": "week9.html#reflection",
    "title": "8  SAR",
    "section": "8.3 Reflection",
    "text": "8.3 Reflection\nThis week’s content on SAR felt both exciting and overwhelming. Compared to optical imagery, SAR is fundamentally different—not only in how data is captured, but also in how it must be processed and interpreted. At first, I wasn’t sure whether the classification and analysis methods we learned in previous weeks still applied here. After doing some research, I found that although classification techniques can be used on SAR data, challenges like speckle noise and phase ambiguity often reduce accuracy. Still, SAR’s strengths—such as its high revisit frequency and ability to operate in all weather conditions—make it invaluable for applications like disaster monitoring and ground deformation tracking. What I take away from this week is that while some techniques are shared across remote sensing data types, SAR requires a specialized workflow with methods like despeckling, coherence analysis, and interferometry. The learning curve is steeper, but the potential is immense—especially if multi-polarisation data can help us understand surface scattering more deeply."
  },
  {
    "objectID": "week2.html#applications",
    "href": "week2.html#applications",
    "title": "1  Getting started with remote sensing",
    "section": "1.2 Applications",
    "text": "1.2 Applications\nRemote sensing has a wide range of applications in environmental monitoring, agriculture, disaster management, urban planning, and security.\nIn environmental studies, satellite imagery helps track deforestation, land use changes, and air and water pollution. High spatial resolution images from satellites like Sentinel-2 and Landsat monitor illegal logging (lima and Beuchle,2019) and urban expansion ((frimpong2021tracking?)) . Spectral resolution data, particularly near-infrared, assesses vegetation health and carbon storage, while satellites like MODIS and Sentinel-5P detect pollutants in the atmosphere and water bodies.\n\nFigure 2 Detail of the sustainable forest management, showing: A) The field data collected, B) the areas classified as disturbed according the Sentinel-2, and C) Landsat 8. Background image\nSource: Lima and Beuchle (2019)\nIn agriculture, remote sensing supports precision farming by monitoring crop health, soil moisture, and irrigation. Multispectral sensors detect plant stress and diseases early, while thermal infrared data tracks soil moisture and evaporation. High-resolution imagery allows for targeted fertilization and pest control, improving efficiency and reducing waste. These technologies help ensure food security by optimizing agricultural production.\nDisaster management heavily relies on remote sensing for early warning and response. Radar satellites like Sentinel-1, with frequent temporal resolution, track flood extent even through cloud cover. Wildfires are detected in real time using thermal infrared sensors, allowing rapid emergency response. Earthquakes and landslides can be predicted and monitored using high spatial and radiometric resolution data, helping assess risk and mitigate damage.\nIn urban planning, remote sensing assists in monitoring city growth, transportation networks, and the heat island effect. Thermal infrared data identifies temperature variations in urban areas, guiding sustainable city development. Traffic patterns and congestion can also be analyzed through satellite imagery, supporting better infrastructure planning.\nSecurity and defense use remote sensing for border surveillance, maritime monitoring, and disaster response. Radar and optical satellites track illegal activities such as smuggling and unauthorized fishing. High temporal resolution images assist in military strategy and humanitarian aid planning."
  },
  {
    "objectID": "week2.html#summary-1",
    "href": "week2.html#summary-1",
    "title": "1  Getting started with remote sensing",
    "section": "1.4 Summary",
    "text": "1.4 Summary\nThis week, the lecture covers an introduction of remote sensing, such as its vast application, instruments, collection method, and things we have to consider when we deal with remote sensing data. I tried to make the summary using visualization below to make it easier to understand."
  },
  {
    "objectID": "week2.html#reflection-1",
    "href": "week2.html#reflection-1",
    "title": "1  Getting started with remote sensing",
    "section": "1.6 Reflection",
    "text": "1.6 Reflection\n\nRemote sensing provides diversity in data source, but…. will the implementation be easy?\n\nAfter exploring the application of the two selected satellites during practical this week, I have concluded that remote sensing data is particularly effective for analyzing large-scale and long-term variations."
  },
  {
    "objectID": "week3.html",
    "href": "week3.html",
    "title": "2  xaringan",
    "section": "",
    "text": "This week I learned to use xaringan which I think is similar with a power point:\n\nxaringanExtra::embed_xaringan(url = \"git上的xiaringanHTML链接\")"
  },
  {
    "objectID": "week4.html#applications",
    "href": "week4.html#applications",
    "title": "3  Corrections",
    "section": "3.2 Applications",
    "text": "3.2 Applications\nA key application of PCA in remote sensing is land use/land cover change detection. Rather than comparing raw spectral bands, PCA transforms multispectral data into uncorrelated principal components, allowing more meaningful patterns to emerge. For instance, a study by Deng et al. (2008) [here] demonstrated that PCA enhanced land-use change detection using multisensor satellite imagery by reducing spectral confusion between classes. A critical issue with PCA, however, is that while it emphasizes major variation, it may suppress minor—but meaningful—changes, which can affect the sensitivity of change detection tasks.\nPCA is also widely used for dimensionality reduction in hyperspectral remote sensing. A 2021 study by Uddin et al. [here] applied PCA as a preprocessing method to reduce noise and redundant information before hyperspectral image classification. The authors found that PCA improved classification accuracy by streamlining input data and reducing confusion in high-dimensional feature space. This highlights how PCA supports cleaner model training and faster computation—though it’s important to note that alternative methods like Minimum Noise Fraction (MNF) may outperform PCA under certain conditions. Ultimately, PCA remains a valuable tool for simplifying complex datasets and enhancing the robustness of remote sensing classification tasks."
  },
  {
    "objectID": "week3.html#xaringan-about-landsat-8-oli",
    "href": "week3.html#xaringan-about-landsat-8-oli",
    "title": "2  xaringan",
    "section": "2.1 Xaringan about Landsat 8 OLI",
    "text": "2.1 Xaringan about Landsat 8 OLI\nThis week I learned to use xaringan which I think is similar with a power point:\n\nxaringanExtra::embed_xaringan(url = \"https://ploverq.github.io/xiaringan/\")"
  }
]